{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "#display first camera calibration image\n",
    "img = mpimg.imread('./camera_cal/calibration1.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The calbration images are read from the camera_cal folder, are transformed to grayscale and the chessboard corners are extracted from each image. If the corners are found correctly (ret == true), their coordinates are appended to the array imgpoints. At the same time the location of the undistorted chessboard corners is appended to the array objpoints. These are the same for each image. Once the data from all images is collected the function calibrateCamera is used to compute the camera matrix mtx (focal length and location of image center) and the distortion coefficients dist for the used camera. These coefficients can then be used to get undistorted camera images. Several images are required during the calibration process to make the optimization more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        #img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(2000)\n",
    "\n",
    "# Compute calibration matrix\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply calibration to test image\n",
    "img = mpimg.imread('./camera_cal/calibration4.jpg')\n",
    "img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define image processing class\n",
    "The image processing class holds all functions that are used to process the images in the later sections of this notebook. These are the following:\n",
    "- load image: load a new image\n",
    "- grayscale: convert to grayscale\n",
    "- gaussian blur: apply gaussian blur filter\n",
    "- canny: gradient based feature extraction\n",
    "- hough: fit lines through the features detected with canny; this function includes a kalman filter that can be used to make the fit more robust by using information from previous frames (e.g. from a video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "class imgproc:\n",
    "    def __init__(self,img):\n",
    "        #image parameters\n",
    "        self.img = img\n",
    "        self.orig = img\n",
    "        #camera parameters\n",
    "        self.mtx = [] #camera matrix (focal length and image center)\n",
    "        self.dist = [] #lens distortion coefficients\n",
    "        self.M = [] # perspective transformation matrix\n",
    "        self.Minv = [] # inverse perspective transformation matrix\n",
    "        #filter parameters\n",
    "        self.A = np.matrix('1 0.04 0 0; 0 1 0 0; 0 0 1 0.04; 0 0 0 1',dtype=np.float)\n",
    "        self.H = np.matrix('1 0 0 0; 0 0 1 0',dtype=np.float)\n",
    "        self.R = np.matrix('0.0001 0; 0 0.0001',dtype=np.float)\n",
    "        self.I = np.matrix('1 0 0 0; 0 1 0 0; 0 0 1 0; 0 0 0 1',dtype=np.float)\n",
    "        self.meas = np.matrix('0;0',dtype=np.float)\n",
    "        self.x_l = np.matrix('0;0;0;0',dtype=np.float)\n",
    "        self.x_r = np.matrix('0;0;0;0',dtype=np.float)\n",
    "        self.P_l = np.matrix('1000 0 0 0; 0 1000 0 0; 0 0 1000 0; 0 0 0 1000',dtype=np.float)\n",
    "        self.P_r = np.matrix('1000 0 0 0; 0 1000 0 0; 0 0 1000 0; 0 0 0 1000',dtype=np.float)\n",
    "        self.filter_init_l = 1\n",
    "        self.filter_init_r = 1\n",
    "        \n",
    "    def ini_tform(self,mtx,dist,M,Minv):\n",
    "        self.mtx = mtx\n",
    "        self.dist = dist\n",
    "        self.M = M\n",
    "        self.Minv = Minv\n",
    "        \n",
    "    def load_image(self,img):\n",
    "        self.img = img\n",
    "        self.orig = img\n",
    "        \n",
    "    def undistort(self):\n",
    "        self.img = cv2.undistort(self.img, self.mtx, self.dist, None, self.mtx)\n",
    "        \n",
    "    def ptransform(self):\n",
    "        self.img = cv2.warpPerspective(self.img, self.M, (self.img.shape[1],self.img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    def grayscale(self):\n",
    "        # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "        self.img = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    def gaussian_blur(self,kernel_size):\n",
    "        self.img = cv2.GaussianBlur(self.img, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    def canny(self,low_threshold, high_threshold):\n",
    "        self.img = cv2.Canny(self.img, low_threshold, high_threshold)\n",
    "        \n",
    "    def region_of_interest(self, vertices):\n",
    "        #defining a blank mask to start with\n",
    "        mask = np.zeros_like(self.img)   \n",
    "    \n",
    "        #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "        if len(self.img.shape) > 2:\n",
    "            channel_count = self.img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "        \n",
    "        #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "        #returning the image only where mask pixels are nonzero\n",
    "        self.img = cv2.bitwise_and(self.img, mask)\n",
    "\n",
    "    def hough_lines(self, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "        color=[255, 0, 0]\n",
    "        thickness=5\n",
    "        bound_ll = -0.85 #left lane gradient lower boundary\n",
    "        bound_lu = -0.55 #left lane gradient upper boundary\n",
    "        bound_rl =  0.45 #right lane gradient lower boundary\n",
    "        bound_ru =  0.75 #right lane gradient upper boundary\n",
    "        lines = cv2.HoughLinesP(self.img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "        line_img = np.zeros((self.img.shape[0], self.img.shape[1], 3), dtype=np.uint8)\n",
    "                \n",
    "        m_seg_l = np.array([]) #gradient of left line segment\n",
    "        b_seg_l = np.array([]) #offset of left line segment\n",
    "        len_seg_l = np.array([]) #length of left line segment\n",
    "        m_seg_r = np.array([])\n",
    "        b_seg_r = np.array([])\n",
    "        len_seg_r = np.array([])\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(line_img, (x1, y1), (x2, y2), [0,255,0], 5)\n",
    "                m = (y2-y1)/(x2-x1) #gradient of line segment\n",
    "                b = y1-m*x1 #offset of line segment\n",
    "                #sort for left and right line\n",
    "                if(bound_ll < m < bound_lu):\n",
    "                    m_seg_l = np.append(m_seg_l,m)\n",
    "                    b_seg_l = np.append(b_seg_l,b)\n",
    "                    len_seg_l = np.append(len_seg_l,np.sqrt(np.power(x2-x1,2)+np.power(y2-y1,2)))\n",
    "                elif(bound_rl < m < bound_ru):\n",
    "                    m_seg_r = np.append(m_seg_r,m)\n",
    "                    b_seg_r = np.append(b_seg_r,b)\n",
    "                    len_seg_r = np.append(len_seg_r,np.sqrt(np.power(x2-x1,2)+np.power(y2-y1,2)))\n",
    "    \n",
    "        #compute weighted average (by segment length) for gradient and offset\n",
    "        b_l = 0\n",
    "        b_r = 0\n",
    "        m_l  = 0\n",
    "        m_r  = 0\n",
    "        for i in range (len(len_seg_l)):\n",
    "            length = np.sum(len_seg_l)\n",
    "            m_l = m_l + m_seg_l[i]*len_seg_l[i]/length\n",
    "            b_l = b_l + b_seg_l[i]*len_seg_l[i]/length\n",
    "        for i in range (len(len_seg_r)):\n",
    "            length = np.sum(len_seg_r)\n",
    "            m_r = m_r + m_seg_r[i]*len_seg_r[i]/length\n",
    "            b_r = b_r + b_seg_r[i]*len_seg_r[i]/length\n",
    "        \n",
    "        #apply filter for gradient and offset and plot line\n",
    "        y1 = int(self.img.shape[0]*2/3)\n",
    "        y2 = int(self.img.shape[0])\n",
    "        if(self.filter_init_l):\n",
    "            if(len(len_seg_l) > 0):\n",
    "                self.x_l[0] = m_l\n",
    "                self.x_l[2] = b_l\n",
    "                cv2.line(line_img, (int((y1-b_l)/m_l), y1), (int((y2-b_l)/m_l), y2), [255,0,0], 10)\n",
    "                self.filter_init_l = False\n",
    "        else:\n",
    "            #predict\n",
    "            self.x_l = self.A*self.x_l\n",
    "            self.P_l = self.A*self.P_l*self.A.transpose()\n",
    "            #correct\n",
    "            if(len(len_seg_l) > 0):\n",
    "                #Kalman filter base code from udacity AI for Robotics\n",
    "                self.meas[0] = m_l\n",
    "                self.meas[1] = b_l\n",
    "                y=self.meas-self.H*self.x_l\n",
    "                S=self.H*self.P_l*self.H.transpose()+self.R\n",
    "                K=self.P_l*self.H.transpose()*inv(S)\n",
    "                self.x_l=self.x_l+(K*y)\n",
    "                self.P_l=(self.I-(K*self.H))*self.P_l\n",
    "            cv2.line(line_img, (int((y1-self.x_l[2])/self.x_l[0]), y1), (int((y2-self.x_l[2])/self.x_l[0]), y2), [255,0,0], 10)\n",
    "    \n",
    "        if(self.filter_init_r):\n",
    "            if(len(len_seg_r) > 0):\n",
    "                self.x_r[0] = m_r\n",
    "                self.x_r[2] = b_r\n",
    "                cv2.line(line_img, (int((y1-b_r)/m_r), y1), (int((y2-b_r)/m_r), y2), [255,0,0], 10)\n",
    "                self.filter_init_r = False\n",
    "        else:\n",
    "            #predict\n",
    "            self.x_r = self.A*self.x_r\n",
    "            self.P_r = self.A*self.P_r*self.A.transpose()\n",
    "            #correct\n",
    "            if(len(len_seg_r) > 0):\n",
    "                self.meas[0] = m_r\n",
    "                self.meas[1] = b_r\n",
    "                y=self.meas-self.H*self.x_r\n",
    "                S=self.H*self.P_r*self.H.transpose()+self.R\n",
    "                K=self.P_r*self.H.transpose()*inv(S)\n",
    "                self.x_r=self.x_r+(K*y)\n",
    "                self.P_r=(self.I-(K*self.H))*self.P_r\n",
    "            cv2.line(line_img, (int((y1-self.x_r[2])/self.x_r[0]), y1), (int((y2-self.x_r[2])/self.x_r[0]), y2), [255,0,0], 10)\n",
    "                        \n",
    "        return line_img, m_l, b_l, m_r, b_r\n",
    "\n",
    "    def weighted_img(self, img, α=0.8, β=1., λ=0.):\n",
    "        self.img = cv2.addWeighted(self.orig, α, img, β, λ)\n",
    "        \n",
    "    def cg_thresh(self):\n",
    "        sobel_kernel = 3\n",
    "        s_thresh = (20,120)\n",
    "        m_thresh = (30,120)\n",
    "        d_thresh = (0.7,1.3)\n",
    "        h_thresh = (150, 255)\n",
    "        \n",
    "        gray = cv2.cvtColor(self.img, cv2.COLOR_RGB2GRAY)\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        \n",
    "        scaled_absx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "        gradx = np.zeros_like(scaled_absx)\n",
    "        gradx[(scaled_absx >= s_thresh[0]) & (scaled_absx <= s_thresh[1])] = 1\n",
    "        \n",
    "        #scaled_absy = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "        #grady = np.zeros_like(scaled_absy)\n",
    "        #grady[(scaled_absy >= s_thresh[0]) & (scaled_absy <= s_thresh[1])] = 1\n",
    "        \n",
    "        mag = np.sqrt(np.square(sobelx)+np.square(sobely))\n",
    "        scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "        mag_binary = np.zeros_like(scaled_mag)\n",
    "        mag_binary[(scaled_mag >= m_thresh[0]) & (scaled_mag <= m_thresh[1])] = 1\n",
    "\n",
    "        dirs = np.arctan2(abs_sobely, abs_sobelx)\n",
    "        dir_binary = np.zeros_like(dirs)\n",
    "        dir_binary[(dirs >= d_thresh[0]) & (dirs <= d_thresh[1])] = 1\n",
    "        \n",
    "        hls = cv2.cvtColor(self.img, cv2.COLOR_RGB2HLS)\n",
    "        S = hls[:,:,2]\n",
    "        hls_binary = np.zeros_like(S)\n",
    "        hls_binary[(S > h_thresh[0]) & (S <= h_thresh[1])] = 1\n",
    "\n",
    "        combined = np.zeros_like(dir_binary)\n",
    "        combined[(gradx == 1) | ((mag_binary == 1) & (dir_binary == 1)) | (hls_binary == 1)] = 1\n",
    "        #combined[((mag_binary == 1) & (dir_binary == 1)) | (hls_binary == 1)] = 1\n",
    "                \n",
    "        self.img = combined\n",
    "        \n",
    "    def find_lanes_1(self):\n",
    "        # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(self.img[np.int(self.img.shape[0]/2):,:], axis=0)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(self.img.shape[0]/nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = self.img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = self.img.shape[0] - (window+1)*window_height\n",
    "            win_y_high = self.img.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "        ploty = np.linspace(0, self.img.shape[0]-1, self.img.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(self.img).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (self.img.shape[1], self.img.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        self.img = cv2.addWeighted(self.orig, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    def find_lanes_2(self):\n",
    "        window_width = 50 \n",
    "        window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "        margin = 80 # How much to slide left and right for searching\n",
    "        offset_h = window_width/2\n",
    "        offset_v = window_height/2\n",
    "        conv_thresh = 50\n",
    "        \n",
    "        window_centroids = [] # Store the left window centroid positions per level\n",
    "        window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "        # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "        # and then np.convolve the vertical image slice with the window template \n",
    "        l_sum = np.sum(self.img[int(self.img.shape[0]/2):,:int(self.img.shape[1]/2)], axis=0)\n",
    "        l_center = np.argmax(np.convolve(window,l_sum))-offset_h\n",
    "        intp_l = np.array([[self.img.shape[0]-offset_v],[l_center]])\n",
    "        r_sum = np.sum(self.img[int(self.img.shape[0]/2):,int(self.img.shape[1]/2):], axis=0)\n",
    "        r_center = np.argmax(np.convolve(window,r_sum))+int(self.img.shape[1]/2)-offset_h\n",
    "        intp_r = np.array([[self.img.shape[0]-offset_v],[r_center]])\n",
    "        \n",
    "        # Add what we found for the first layer\n",
    "        window_centroids.append((l_center,r_center)) # location for drawing left and richt search windows\n",
    "            \n",
    "        # Go through each layer looking for max pixel locations\n",
    "        for level in range(1,(int)(self.img.shape[0]/window_height)):\n",
    "            # convolve the window into the vertical slice of the image\n",
    "            image_layer = np.sum(self.img[int(self.img.shape[0]-(level+1)*window_height):int(self.img.shape[0]-level*window_height),:], axis=0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "            # Find the best left centroid by using past left center as a reference\n",
    "            l_min_index = int(max(l_center+offset_h-margin,0))\n",
    "            l_max_index = int(min(l_center+offset_h+margin,self.img.shape[1]))\n",
    "            if(np.max(conv_signal[l_min_index:l_max_index])>conv_thresh):\n",
    "                l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset_h\n",
    "                intp_l = np.append(intp_l,np.array([[self.img.shape[0]-level*window_height-offset_v],[l_center]]),axis=1)\n",
    "            # Find the best right centroid by using past right center as a reference\n",
    "            r_min_index = int(max(r_center+offset_h-margin,0))\n",
    "            r_max_index = int(min(r_center+offset_h+margin,self.img.shape[1]))\n",
    "            if(np.max(conv_signal[r_min_index:r_max_index])>conv_thresh):\n",
    "                r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset_h\n",
    "                intp_r = np.append(intp_r,np.array([[self.img.shape[0]-level*window_height-offset_v],[r_center]]),axis=1)\n",
    "            # Add what we found for that layer\n",
    "            window_centroids.append((l_center,r_center))\n",
    "        \n",
    "        # fit polynomial through int_l and int_r points\n",
    "        left_fit, residuals_l, rank_l, singular_values_l, rcond_l = np.polyfit(intp_l[0,:], intp_l[1,:], 2, full=True)\n",
    "        #print('residuals=',residuals_l,' rank=',rank_l,' rcondl=',rcond_l)\n",
    "        right_fit, residuals_r, rank_r, singular_values_r, rcond_r = np.polyfit(intp_r[0,:], intp_r[1,:], 2, full=True)\n",
    "        #print('residuals=',residuals_r,' rank=',rank_r,' rcondl=',rcond_r)\n",
    "                \n",
    "#        ### Draw lines in projected image ###\n",
    "#        # If we found any window centers\n",
    "#        if len(window_centroids) > 0:\n",
    "#            # Points used to draw all the left and right windows\n",
    "#            l_points = np.zeros_like(self.img)\n",
    "#            r_points = np.zeros_like(self.img)\n",
    "#            # Go through each level and draw the windows\n",
    "#            for level in range(0,len(window_centroids)):\n",
    "#                # Window_mask is a function to draw window areas\n",
    "#                l_mask = window_mask(window_width,window_height,self.img,window_centroids[level][0],level)\n",
    "#                r_mask = window_mask(window_width,window_height,self.img,window_centroids[level][1],level)\n",
    "#                # Add graphic points from window mask here to total pixels found \n",
    "#                l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "#                r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "#            # Draw the results\n",
    "#            template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "#            zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "#            template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "#            warpage = np.array(cv2.merge((self.img*255,self.img*255,self.img*255)),np.uint8) # making the original road pixels 3 color channels\n",
    "#            self.img = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "#        # If no window centers found, just display orginal road image\n",
    "#        else:\n",
    "#            self.img = np.array(cv2.merge((self.img*255,self.img*255,self.img*255)),np.uint8)\n",
    "\n",
    "        ploty = np.linspace(0, self.img.shape[0]-1, self.img.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(self.img).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (self.img.shape[1], self.img.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        self.img = cv2.addWeighted(self.orig, 1, newwarp, 0.3, 0)\n",
    "            \n",
    "        #return left_fit, right_fit\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return repr(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute perspective transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the lanes are computed for a test image by using the functions from class imgproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = imgproc(mpimg.imread('./test_images/straight_lines2.jpg'))\n",
    "#apply distortion correction\n",
    "frame.mtx = mtx\n",
    "frame.dist = dist\n",
    "frame.undistort()\n",
    "#convert to grayscale\n",
    "frame.grayscale()\n",
    "# apply gaussian blur\n",
    "frame.gaussian_blur(5)\n",
    "# perform edge detection\n",
    "frame.canny(100,200)\n",
    "# cut out ROI\n",
    "imshape = frame.img.shape\n",
    "vertices = np.array([[(1/7*imshape[1],imshape[0]-40),(2/5*imshape[1], 3/5*imshape[0]), (3/5*imshape[1], 3/5*imshape[0]), (9/10*imshape[1],imshape[0]-40)]], dtype=np.int32)\n",
    "frame.region_of_interest(vertices)\n",
    "# select lines from image [hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap)]\n",
    "hough, m_l, b_l, m_r, b_r = frame.hough_lines(1, np.pi/180, 40, 20, 5)\n",
    "# compute weighted image [weighted_img(img, initial_img, α=0.8, β=1., λ=0.)]\n",
    "frame.weighted_img(hough, α=0.8, β=1., λ=0.)\n",
    "# plot image\n",
    "plt.figure()\n",
    "plt.imshow(frame.img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute the perspective transformation matrix M\n",
    "y_min = 460\n",
    "y_max = imshape[0]\n",
    "src = ([(y_min-b_l)/m_l,y_min],[(y_min-b_r)/m_r,y_min],[(y_max-b_r)/m_r,y_max],[(y_max-b_l)/m_l,y_max])\n",
    "src = np.float32(src)\n",
    "dst = np.float32([[250,0],[1030,0],[1030,720],[250,720]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "#store transformation matrix in imgproc\n",
    "frame.M = M\n",
    "frame.Minv = Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test images and perform perspective correction and image transform\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "#images = glob.glob('./test_images/straight_lines*.jpg')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "i=0\n",
    "for img in images:\n",
    "    frame.load_image(mpimg.imread(img))\n",
    "    frame.undistort()\n",
    "    #frame.ptransform()\n",
    "    i=i+1\n",
    "    plt.subplot(2,3,i)\n",
    "    plt.imshow(frame.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "i=0\n",
    "for img in images:\n",
    "    frame.load_image(mpimg.imread(img))\n",
    "    frame.undistort()\n",
    "    frame.cg_thresh()\n",
    "    i=i+1\n",
    "    plt.subplot(2,3,i)\n",
    "    plt.imshow(frame.img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "i=0\n",
    "for img in images:\n",
    "    frame.load_image(mpimg.imread(img))\n",
    "    frame.undistort()\n",
    "    frame.cg_thresh()\n",
    "    frame.ptransform()\n",
    "    i=i+1\n",
    "    plt.subplot(2,3,i)\n",
    "    plt.imshow(frame.img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. with test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "i=0\n",
    "for img in images:\n",
    "    frame.load_image(mpimg.imread(img))\n",
    "    frame.undistort()\n",
    "    frame.cg_thresh()\n",
    "    frame.ptransform()\n",
    "    frame.find_lanes_2()\n",
    "    i=i+1\n",
    "    plt.subplot(2,3,i)\n",
    "    plt.imshow(frame.img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. with test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    frame.load_image(image)\n",
    "    frame.undistort()\n",
    "    frame.cg_thresh()\n",
    "    frame.ptransform()\n",
    "    frame.find_lanes_2()\n",
    "    \n",
    "    return frame.img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = 'test_videos_output/project_video.mp4'\n",
    "video_input = VideoFileClip(\"project_video.mp4\")\n",
    "global frame\n",
    "frame = imgproc([])\n",
    "frame.ini_tform(mtx,dist,M,Minv)\n",
    "clip = video_input.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = 'test_videos_output/challenge_video.mp4'\n",
    "video_input = VideoFileClip(\"challenge_video.mp4\")\n",
    "global frame\n",
    "frame = imgproc([])\n",
    "frame.ini_tform(mtx,dist,M,Minv)\n",
    "clip = video_input.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = 'test_videos_output/harder_challenge_video.mp4'\n",
    "video_input = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "global frame\n",
    "frame = imgproc([])\n",
    "frame.ini_tform(mtx,dist,M,Minv)\n",
    "clip = video_input.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
